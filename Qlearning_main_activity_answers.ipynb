{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "goal_reward = 1\n",
    "nongoal_reward = -0.2\n",
    "learning_rate =0.5\n",
    "discount = 2\n",
    "initial_q_value_range = (-2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env():\n",
    "    def __init__(self):\n",
    "        self.height = 5\n",
    "        self.width = 5\n",
    "        self.posX = 0\n",
    "        self.posY = 0\n",
    "        self.endX = self.width-1\n",
    "        self.endY = self.height-1\n",
    "        self.actions = [0, 1, 2, 3]\n",
    "        self.stateCount = self.height*self.width\n",
    "        self.actionCount = len(self.actions)\n",
    "        self.step_count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.posX = 0\n",
    "        self.posY = 0\n",
    "        self.step_count = 0\n",
    "        self.done = False\n",
    "        return 0, 0, False\n",
    "\n",
    "    # take action\n",
    "    def step(self, action):\n",
    "        if action==0: # left\n",
    "            self.posX = self.posX-1 if self.posX>0 else self.posX\n",
    "        if action==1: # right\n",
    "            self.posX = self.posX+1 if self.posX<self.width-1 else self.posX\n",
    "        if action==2: # up\n",
    "            self.posY = self.posY-1 if self.posY>0 else self.posY\n",
    "        if action==3: # down\n",
    "            self.posY = self.posY+1 if self.posY<self.height-1 else self.posY\n",
    "\n",
    "        done = self.posX==self.endX and self.posY==self.endY;\n",
    "        # mapping (x,y) position to number between 0 and 5x5-1=24\n",
    "        nextState = self.width*self.posY + self.posX\n",
    "        reward = goal_reward if done else nongoal_reward\n",
    "        self.step_count += 1\n",
    "        return nextState, reward, done\n",
    "\n",
    "    # display environment\n",
    "    def render(self):\n",
    "        ret = \"\"\n",
    "        for i in range(self.height):\n",
    "            for j in range(self.width):\n",
    "                if self.posY==i and self.posX==j:\n",
    "                    ret += \"O\"\n",
    "                elif self.endY==i and self.endX==j:\n",
    "                    ret += \"T\"\n",
    "                else:\n",
    "                    ret += \".\"\n",
    "            ret += \"\\n\"\n",
    "        print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create environment\n",
    "env = Env()\n",
    "\n",
    "# QTable : contains the Q-Values for every (state,action) pair\n",
    "qtable = np.random.uniform(low=initial_q_value_range[0], high=initial_q_value_range[1], size=(env.stateCount, env.actionCount))\n",
    "\n",
    "# training loop\n",
    "epochs = 50\n",
    "for i in range(epochs):\n",
    "    state, reward, done = env.reset()\n",
    "\n",
    "    while not done:\n",
    "        clear_output(wait=True)\n",
    "        print(\"epoch #\", i+1, \"/\", epochs)\n",
    "        env.render()\n",
    "        print(qtable)\n",
    "        \n",
    "        time.sleep(0.05) #So that movement is visible\n",
    "        \n",
    "        # Choose an action to take\n",
    "        #action = {Problem 1}\n",
    "        #current_q = {Problem 1}\n",
    "\n",
    "        # take action\n",
    "        next_state, reward, done = env.step(action)\n",
    "\n",
    "        # update qtable value with update equation\n",
    "       # qtable[state][action] = {Problem 2}\n",
    "\n",
    "        # update state\n",
    "        state = next_state\n",
    "    \n",
    "    print(f\"Done in {env.step_count} steps\")\n",
    "    time.sleep(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
