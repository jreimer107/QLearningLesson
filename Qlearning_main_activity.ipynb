{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "goal_reward = 1\n",
    "nongoal_reward = -0.2\n",
    "learning_rate =0.5\n",
    "discount = 2\n",
    "initial_q_value_range = (-2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env():\n",
    "    def __init__(self):\n",
    "        self.height = 5\n",
    "        self.width = 5\n",
    "        self.posX = 0\n",
    "        self.posY = 0\n",
    "        self.endX = self.width-1\n",
    "        self.endY = self.height-1\n",
    "        self.actions = [0, 1, 2, 3]\n",
    "        self.stateCount = self.height*self.width\n",
    "        self.actionCount = len(self.actions)\n",
    "        self.step_count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.posX = 0\n",
    "        self.posY = 0\n",
    "        self.step_count = 0\n",
    "        self.done = False\n",
    "        return 0, 0, False\n",
    "\n",
    "    # take action\n",
    "    def step(self, action):\n",
    "        if action==0: # left\n",
    "            self.posX = self.posX-1 if self.posX>0 else self.posX\n",
    "        if action==1: # right\n",
    "            self.posX = self.posX+1 if self.posX<self.width-1 else self.posX\n",
    "        if action==2: # up\n",
    "            self.posY = self.posY-1 if self.posY>0 else self.posY\n",
    "        if action==3: # down\n",
    "            self.posY = self.posY+1 if self.posY<self.height-1 else self.posY\n",
    "\n",
    "        done = self.posX==self.endX and self.posY==self.endY;\n",
    "        # mapping (x,y) position to number between 0 and 5x5-1=24\n",
    "        nextState = self.width*self.posY + self.posX\n",
    "        reward = goal_reward if done else nongoal_reward\n",
    "        self.step_count += 1\n",
    "        return nextState, reward, done\n",
    "\n",
    "    # display environment\n",
    "    def render(self):\n",
    "        ret = \"\"\n",
    "        for i in range(self.height):\n",
    "            for j in range(self.width):\n",
    "                if self.posY==i and self.posX==j:\n",
    "                    ret += \"O\"\n",
    "                elif self.endY==i and self.endX==j:\n",
    "                    ret += \"T\"\n",
    "                else:\n",
    "                    ret += \".\"\n",
    "            ret += \"\\n\"\n",
    "        print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch # 1 / 50\n",
      "O....\n",
      ".....\n",
      ".....\n",
      ".....\n",
      "....T\n",
      "\n",
      "[[-1.49640058 -1.31325464 -0.62558035 -0.55308248]\n",
      " [-1.75068279 -1.06501282 -0.17574873 -1.94136892]\n",
      " [-0.29131243 -1.61434734 -0.20398675 -1.40514089]\n",
      " [-1.12162226 -1.19054469 -0.73640138 -0.52832421]\n",
      " [-1.26313646 -0.75375888 -0.79189059 -1.65325737]\n",
      " [-0.94056716 -0.32451554 -1.06043589 -1.29243144]\n",
      " [-0.90518226 -1.97565932 -1.41758584 -1.040678  ]\n",
      " [-0.57527565 -1.33149986 -1.07259632 -1.03215822]\n",
      " [-1.46076119 -0.07639011 -0.37897172 -0.59979697]\n",
      " [-0.80754897 -1.12811088 -1.50928597 -0.8076878 ]\n",
      " [-1.04746517 -1.62585299 -0.77962829 -1.97219865]\n",
      " [-0.46472806 -1.44276031 -1.50751724 -1.7641352 ]\n",
      " [-1.05888189 -1.87267569 -0.88196391 -1.43623992]\n",
      " [-0.19235552 -0.99699126 -0.01249772 -1.61213659]\n",
      " [-0.3420593  -0.75537159 -1.10704685 -1.23504836]\n",
      " [-0.00799782 -0.02538458 -0.28712833 -1.83678943]\n",
      " [-1.3986005  -1.4028128  -1.25416156 -0.35858636]\n",
      " [-1.5932906  -0.03481109 -0.12524989 -0.68744255]\n",
      " [-0.58961439 -0.84530592 -0.81685683 -0.32528996]\n",
      " [-1.74321164 -0.03462518 -0.15347165 -0.83907213]\n",
      " [-1.86376324 -0.64988047 -0.13182342 -0.37320786]\n",
      " [-0.94712791 -0.47896358 -1.07771053 -0.3668708 ]\n",
      " [-1.18883594 -0.39840082 -1.01877626 -0.87324895]\n",
      " [-1.87403659 -0.53907206 -1.55134013 -0.03168733]\n",
      " [-1.77347577 -0.22045034 -1.87069039 -0.30101617]]\n"
     ]
    }
   ],
   "source": [
    "# create environment\n",
    "env = Env()\n",
    "\n",
    "# QTable : contains the Q-Values for every (state,action) pair\n",
    "qtable = np.random.uniform(low=initial_q_value_range[0], high=initial_q_value_range[1], size=(env.stateCount, env.actionCount))\n",
    "\n",
    "# training loop\n",
    "epochs = 50\n",
    "for i in range(epochs):\n",
    "    state, reward, done = env.reset()\n",
    "\n",
    "    while not done:\n",
    "        clear_output(wait=True)\n",
    "        print(\"epoch #\", i+1, \"/\", epochs)\n",
    "        env.render()\n",
    "        print(qtable)\n",
    "        \n",
    "        time.sleep(0.05) #So that movement is visible\n",
    "        \n",
    "        # Choose an action to take\n",
    "        #action = {Problem 1}\n",
    "        #current_q = {Problem 1}\n",
    "\n",
    "        # take action\n",
    "        next_state, reward, done = env.step(action)\n",
    "\n",
    "        # update qtable value with update equation\n",
    "       # qtable[state][action] = {Problem 2}\n",
    "\n",
    "        # update state\n",
    "        state = next_state\n",
    "    \n",
    "    print(f\"Done in {env.step_count} steps\")\n",
    "    time.sleep(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
